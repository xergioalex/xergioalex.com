---
title: "How AI is Revolutionizing Modern Application Development"
description: "What changed between May and August 2023 — my Manizales Tech Talks experience sharing how AI was transforming app development, three months deeper into the revolution."
pubDate: "2023-08-26"
heroImage: "/images/blog/posts/ai-rebirth-manizales/hero.png"
heroLayout: "side-by-side"
tags: ["talks", "tech"]
---

Three months after Pereira, I was back on stage — this time in Manizales. Same core story, but everything had evolved. Between May and August 2023, the AI landscape shifted fast enough that I found myself rewriting slides the night before. Not because the foundation changed, but because we'd crossed new milestones. More developers were shipping with GPT-4. More teams were experimenting. More real products were being built on AI that didn't exist a year ago.

This wasn't a repeat. It was a checkpoint — seeing how much the conversation had matured in just a few months.

---

## Why Manizales Felt Different

The Pereira audience in May had been curious — some skeptical, some excited, all exploring. By August in Manizales, the questions changed. People weren't asking *if* they should care about AI — they were asking *what* to build with it and *how* to actually start. That shift told me something had clicked in the ecosystem. This wasn't hype anymore. It was practical interest from engineers who wanted to ship.

Manizales also brought a different energy — a smaller, more intimate setting. Conversations after the talk went deeper. I had more time to talk through use cases, troubleshoot blockers, and share what we'd learned at DailyBot in the months since GPT-4's launch.

---

## What Changed in 3 Months

Between May and August, the tooling matured. **GPT-4** had gone from a shiny new release to something people were building production features on. I saw it in our own work at DailyBot — what started as experiments in April were now live integrations our users relied on.

**LangChain** and **vector databases** had become part of the conversation. In May, I'd mentioned retrieval-augmented generation (RAG) as a concept. By August, I was showing practical examples — how to connect a language model to your own data, how to build search and Q&A systems that actually worked. The abstractions were getting better, and the barrier to entry was dropping fast.

I also noticed more clarity around where AI *should* and *shouldn't* be used. In May, people were throwing AI at everything to see what stuck. By August, the patterns were clearer: AI excels at summarization, transformation, ideation, and conversational interfaces. It struggles with precision, consistency, and anything requiring deterministic correctness. That nuance mattered.

---

## From GPT-4 to Real Applications

In Pereira I'd shown what GPT-4 could do — multimodal, long context, better reasoning. In Manizales I shifted the focus to *what people were actually building* with it:

- **Customer support automations** that could understand context and respond naturally without rigid scripts
- **Documentation search** powered by embeddings and RAG — no more hunting through wikis
- **Content generation workflows** where AI handled the first draft and humans refined
- **Developer tools** like smarter autocomplete, code explanations, and debugging assistants

This wasn't future talk. These were tools I'd used, products my peers were shipping, and workflows we were refining in real time. That grounded the conversation in a way that felt more honest.

---

## The Conductor Metaphor Takes Shape

In May I'd introduced the idea: you're not just coding anymore, you're orchestrating. By August I'd lived that shift long enough to explain it better. You become a conductor — you define the goal, the agent generates options, you choose the direction. You handle judgment, creativity, and taste. The agent handles execution, iteration, and scale.

At Manizales I spent more time on this mindset because I'd seen it work. The developers who adapted fastest weren't the ones writing the best prompts (though that helped). They were the ones who understood systems thinking, knew their product deeply, and could evaluate AI output critically. Those skills mattered more than ever.

---

## Practical Takeaways for the Audience

I ended with what I'd learned in practice since May:

1. **Start small, iterate fast** — Don't try to rebuild your whole product with AI. Pick one workflow, automate it, see what breaks.
2. **Understand the limits** — AI is a tool, not magic. Know when to use it and when to stick with traditional approaches.
3. **Build feedback loops** — The best AI-powered features improve over time. Design systems that learn from user input.
4. **Keep the human in the loop** — Especially for anything customer-facing or high-stakes. AI assists, humans decide.

---

## Event Memories

<div class="grid grid-cols-2 gap-4 not-prose">
  <img src="/images/blog/posts/ai-rebirth-manizales/memory-1.jpg" alt="Talk presentation with title slide" width="600" height="400" class="rounded-xl object-cover w-full aspect-[4/3]" loading="lazy" />
  <img src="/images/blog/posts/ai-rebirth-manizales/memory-2.jpg" alt="Speaker presenting to audience" width="600" height="400" class="rounded-xl object-cover w-full aspect-[4/3]" loading="lazy" />
  <img src="/images/blog/posts/ai-rebirth-manizales/memory-3.jpg" alt="State of the art slide during AI Rebirth talk" width="600" height="400" class="rounded-xl object-cover w-full aspect-[4/3]" loading="lazy" />
</div>

---

## Recording

<div class="aspect-video w-full max-w-3xl rounded-xl overflow-hidden my-6">
  <iframe src="https://www.youtube.com/embed/569TV50FDUE" title="AI Rebirth — Manizales full talk recording" width="560" height="315" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen class="w-full h-full"></iframe>
</div>

[View slides (Manizales)](https://docs.google.com/presentation/d/1CqWtoNAwq1lN-WSsFJE6Pjxezi9EfSuLTMjoPWyCf90/edit)

Let's keep building.
